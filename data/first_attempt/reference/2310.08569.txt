ABSTRACT
Modern commercial Heating, Ventilation, and Air Conditioning
(HVAC) devices form a complex and interconnected thermody-
namic system with the building and outside weather conditions,
and current setpoint control policies are not fully optimized for
minimizing energy use and carbon emission. Given a suitable train-
ing environment, a Reinforcement Learning (RL) model is able to
improve upon these policies, but training such a model, especially
in a way that scales to thousands of buildings, presents many real
world challenges. We propose a novel simulation-based approach,
where a customized simulator is used to train the agent for each
building. Our open-source simulator1 is lightweight and calibrated
via telemetry from the building to reach a higher level of fidelity. On
a two-story, 68,000 square foot building, with 127 devices, we were
able to calibrate our simulator to have just over half a degree of drift
from the real world over a six-hour interval. This approach is an
important step toward having a real-world RL control system that
can be scaled to many buildings, allowing for greater efficiency and
resulting in reduced energy consumption and carbon emissions.

KEYWORDS
HVAC Optimization, Simulation, Reinforcement Learning

ACM Reference Format:
Judah Goldfeder and John Sipple. 2023. A Lightweight Calibrated Simulation
Enabling Efficient Offline Learning for Optimal Control of Real Buildings.
In Proceedings of RLEM â€™23. ACM, New York, NY, USA, 5 pages. https://doi.
org/XXXXXXX.XXXXXXX

1 