Introduction Probabilities of Causation (PoC) play a fundamental role in decision-making in law, health care and public policy (Mueller and Pearl 2022; Faigman, Monahan, and Slobogin 2014). For example, in medical applications, if a medication for a disease has similar side effects to the disease itself, we must calculate the probability that the adverse side ef- fect was caused by the medication, for safety assessments. In epidemiology, we often need to determine the likelihood that a particular outcome is caused by a specific exposure, or if a particular subgroup that experienced an adverse outcome would benefit from an intervention. Probabilities of Causa- tion defined in (Pearl 2009) provide a logical framework to reason about such counterfactuals, as well as necessary as- sumptions required to identify them from the observed data. While causal parameters such as the Average Treatment Effect are point identified from the observed data distribu- tion, under reasonable assumptions, such as exogeneity, PoC are not. Specifically, in addition to exogeneity, these require monotonicity to hold for point identification (Pearl 2022; Khoury et al. 1989). However, when we do not have suffi- cient justification for assuming monotonicity, then, the PoC are no longer point identified. Rather, PoC are partially iden- tified, i.e. bounded as a function of the observed data. There exists a rich literature on partial identification and its use in bounding causal quantities; some examples in- clude (Manski 1990; Tian and Pearl 2000; Balke and Pearl 1994; Robins and Greenland 1989; Dawid, Musio, and Murtas 2017). The specific question of bounding PoC has also been explored in (Tian and Pearl 2000; Zhang, Tian, and Bareinboim 2022; Cuellar 2018; Robins and Green- land 1989; Dawid, Musio, and Murtas 2017; Padh et al. 2022; Sachs et al. 2022), however, this body of literature assumes the joint probability distribution for the variables of interest is known. Our contribution differs fundamen- tally from existing work in that we do not assume access to the joint probability distribution for the variables of in- terest. Rather, we consider the case where multiple datasets of non-overlapping treatments that study the same outcome are given. Specifically, consider the target dataset containing treatment X and outcome Z. In addition, we are given an ex- ternal dataset that studies the same outcome Z, and contains different treatment or covariates Y which are randomised and independent of X. We demonstrate how to merge the external dataset with the target dataset to tighten the bounds on the PoC of X on Z, while allowing for the treatment X to be confounded in the external dataset. We demonstrate the importance of this scenario using the following example. Suppose we have treatment X (medication) for a disease, and an adverse side effect Z, that could be caused by the disease or the medication itself. Suppose X is randomized, and for safety reasons, we are interested in calculating the probability that X caused Z. The Probabilities of Causation provide a logical framework to reason about this probability, so we aim to calculate it using the observed data. Since we don’t know whether the medication is protective or harm- ful, we are not justified in assuming monotonicity. Then, the Probabilities of Causation are no longer point identified, and we must settle for bounds on them. Given the target dataset containing observations on X and Z, these bounds can be calculated - however, these bounds may be too wide for us to arrive at a conclusion. Re-running the study on the same population while recording a richer set of covariates is not an option due to time and financial constraints. This raises the question “Can other external datasets, studying the same adverse effect on similar populations, but not necessar- ily studying the same treatment, be leveraged to tighten the bounds on the PoC in the target dataset?” While Zhang, Tian, and Bareinboim 2022; Li and Pearl 2022; Pearl 2022; Cuellar 2018; Dawid, Musio, and Murtas 2017 tighten bounds on the Probabilities of Causation (and more generally, other counterfactuals), they all assume ac- cess to a dataset recording all of the variables of interest. Therefore, such bounds cannot be straightforwardly applied to use cases like the one we described above. To address this gap, in this paper we focus on the challenging cases that assume only access to datasets that contain the same out- come, but do not record X and Y at the same time. These datasets can differ in their treatment assignment mechanism for X, allowing it to be randomized or confounded (as- suming a sufficient set of confounders is observed). While Duarte et al. 2021; Zeitler and Silva 2022 do not need ac- cess to the joint distributions over all the variables, the bounds that they provide are only numerical. Here, we pro- vide symbolic bounds. Additionally, the linear programming approach in (Balke and Pearl 1994) cannot be applied for the bound estimation since the dual of the linear program would still have symbolic constraints. From a non-causal perspec- tive, Charitopoulos, Papageorgiou, and Dua 2018 present a symbolic linear programming approach. However, knowing which constraints to supply to the linear program to derive bounds in the problem we describe requires knowledge of the causal graph and invariances. As we show in this paper, these constraints are not trivial to derive. Moreover, the so- lution in (Charitopoulos, Papageorgiou, and Dua 2018) only works for fixed dimensionality for Y , since different dimen- sionalities of Y correspond to different linear programs. In our work, we explicitly target the aforementioned use case allowing arbitrary dimensionality of Y . Structure and Contributions We start by reviewing the structural causal model (SCM) framework and its seman- tics for counterfactual reasoning (§2). Counterfactuals are the basis of the Probabilities of Causation, which we intro- duce in §3. In this section, we formally state the Probability of Sufficiency and Necessity, and we review existing bounds on it. In §4 we describe the data-generating process for the target and external datasets. We then describe the assumed invariances, and how these can be used to transfer informa- tion across datasets. Leveraging this invariance principle, we present theorems that provide symbolic bounds on the PoC in our target dataset, after merging it with an external dataset containing a randomized covariate or treatment of arbitrary dimensionality. In §4.3 we further relax the strict assumption of X being randomized in the external dataset, and provide symbolic bounds in the presence of observed confounding. We conclude with remarks in §5. We provide all our proofs and derivations in the Technical Appendix. 2 Preliminaries While there exist many formulations of causal models in the literature, such as the Finest Fully Randomized Causally In- terpretable Structured Tree Graph (FFRCISTG) of (Robins 1986) and the agnostic causal model of (Spirtes et al. 2000), in this work, we utilise the SCM defined in (Pearl 2009). For- mally, a SCM M is defined as a tuple ⟨U, V, F, P⟩ where U and V represent a set of exogenous and endogenous random variables respectively. F represents a set of functions that determine the value of V ∈ V through v ← fV (paV , uV ) where paV denotes the parents of V and uV denotes the val- ues of the noise variables relevant to V . P denotes the joint distribution over the set of noise variables U, and since the noise variables U are assumed to be mutually independent, the joint distribution P(U) factorises into the product of the marginals of the individual noise distributions. M induces an observational data distribution on V, and is associated with a Directed Acyclic Graph (DAG) G. Defining an SCM allows us to define submodels, potential responses and counterfactuals, as defined in (Pearl 2009). Given a causal model M and a realisation x of random vari- ables X ⊂ V, a submodel Mx corresponds to deleting from F all functions that set values of elements in X and replac- ing them with constant functions X = x. The submodel captures the effect of intervention do(X = x) on M. Given a subset Y ⊂ V, the potential response Yx(u) denotes the values of Y that satisfy Mx given value u of the exogenous variables U. Thus, the counterfactual Yx(u) = y represents the scenario where the potential response Yx(u) is equal to y, if we possibly contrary to fact, set X = x. When u is generated from P (U), we obtain counterfactual random variables Yx that have a corresponding probability distri- bution. Counterfactual random variables lie on rung three of the Ladder of Causation (Pearl 2009), needing additional as- sumptions for their identification. In the following section, we explore a special class of counterfactual probabilities, known as the Probabilities of Causation. 3 Probabilities of Causation An important class of counterfactual probabilities that have applications in law, medicine, and public policy are known as the Probabilities of Causation (Pearl 2009). These are a set of five counterfactual probabilities related to the Proba- bility of Necessity and Sufficiency (P N S), which we define as follows. Consider the causal graph in Fig. 1, where the outcome Z and treatment X are binary random variables. Figure 1: Causal graph containing treatment X and outcome Z, where treatment X is randomized Let x denote the event that the random variable X has value 1 and let x′ denote the event that X has value 0. Then, the P N S is defined as P N S ≡ P (Zx = 1, Zx′ = 0) (1) XZ1 P N S represents the joint probability that the counterfactual random variable Zx takes on value 1 and the counterfactual random variable Zx′ takes on value 0. Under conditions of exogeneity, defined as Zx ⊥⊥ X, the rest of the Probabil- ities of Causation such as Probability of Necessity (P N ) and Probability of Sufficiency (P S), are all defined as func- tions of P N S (see Theorem 9.2.11 in (Pearl 2009)). Conse- quently, when P N S is identified, all the other Probabilities of Causation are straightforwardly identified from the ob- served data as well. However, to identify P N S, we must make assumptions such as monotonocity (Tian and Pearl 2000), which may not be justified in settings involving experimental drugs, legal matters and occupational health. Without this assumption, P N S is no longer point identified, but it can still be mean- ingfully bounded using tools from the partial identification literature. Assuming still the graph in Fig. 1, an important bound on P N S is defined in Tian and Pearl (2000), and is presented below, with p11, p10 and p00 denoting P (Z = 1 | X = 1), P (Z = 1 | X = 0), and P (Z = 0 | X = 0) respectively. max (cid:21) (cid:20) 0 p11 − p10 ≤ P N S ≤ min (cid:21) (cid:20)p11 p00 (2) Given additional data (i.e. Y in Fig. 2), the bounds on P N S can be further tightened, as shown in Dawid, Musio, and Murtas (2017). We present one of their results here, as we utilize this to tighten the bounds on the Probabilities of Cau- sation by merging target and external datasets. In Fig. 2, X Dawid, Musio, and Murtas 2017 show that this interval is always contained in the one given in Eq. 2. Note that the bounds in Eq. 3 assume access to the joint distribution P (Z, X, Y ). In the use case we tackle in this paper, we do not have this luxury. On the contrary, we are given a target dataset that studies a treatment X and an outcome Z, and additional in- formation in the form of an external dataset with the same outcome Z, that studies a different treatment (or covariate) Y which is randomized and independent of X. We denote 2 the distribution associated with the target dataset as P T , and the distribution associated with the external dataset as P E. We are interested in using this external dataset to tighten the bounds on the PNS of X on Z in our target dataset. In other words, we do not have access to the joint distribution P T (Z, X, Y ) for our target dataset, rather, we only have ac- cess to P T (Z, X). Hence, we cannot straightforwardly ap- ply the bounds in Eq. 3. To this end, we borrow information from the external dataset to constrain the possible choices for the target dis- tribution P T (Z, X, Y ). Typically, the target distribution is not identified, and as such, we constrain the set of possible distributions compatible with both our target and external datasets. Then, we can utilize Eq. 3 to pick the most conser- vative bounds implied by the set of joint distributions which are compatible with the target and the external dataset. Formally, let i index this set of compatible joint distribu- tions. Then the most conservative bound will be the small- est lower bound on P N S, and the greatest upper bound on P N S. Denoting P T (Z = 1 | X = 1) as pT 11, the bounds are given as min P T i ∆(P T i ) ≤ P N S ≤ max P T i 11 − Γ(P T pT i ) (4) From the properties of the max operator, and since pT known, the bounds in Eq. 4 and are re-written as 11 is Figure 2: Causal graph containing binary treatment