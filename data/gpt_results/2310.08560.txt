INTRODUCTION large language models (LLMs) and their underlying transformer architec- In recent years, ture (Vaswani et al., 2017; Devlin et al., 2018; Brown et al., 2020; Ouyang et al., 2022) have become the cornerstone of conversational AI and have led to a wide array of consumer and enterprise applica- tions. Despite these advances, the limited fixed-length context windows used by LLMs significantly hinders their applicability to long conversations or reasoning about long documents. For example, the most widely used open-source LLMs can only support a few dozen back-and-forth messages or reason about a short document before exceeding their maximum input length (Touvron et al., 2023). Naively extending the context length of transformers incurs a quadratic increase in computational time and memory cost due to the transformer architecture‚Äôs self-attention mechanism, making the design of new long-context architectures a pressing research challenge (Dai et al., 2019; Kitaev et al., 2020; Beltagy et al., 2020). While developing longer models is an active area of research (Dong et al., 2023), even if we could overcome the computational challenges of context scaling, recent research shows that long-context models struggle to utilize additional context effectively (Liu et al., 2023a). As consequence, given the considerable resources needed to train state-of-the-art LLMs and apparent diminishing returns of context scaling, there is a critical need for alternative techniques to support long context. In this paper, we study how to provide the illusion of an infinite context while continuing to use fixed-context models. Our approach borrows from the idea of virtual memory paging that was developed to enable applications to work on datasets that far exceed the available memory. We leverage the recent progress in function calling abilities of LLM agents (Schick et al., 2023; Liu et al., 2023b) to design MemGPT, an OS-inspired LLM system for virtual context management. We draw inspiration from traditional OSes‚Äô hierarchical memory management to effectively ‚Äúpage‚Äù in 1 Preprint Figure 1: In MemGPT (components shaded), a fixed-context LLM is augmented with a hierarchical memory system and functions that let it manage its own memory. The LLM processor takes main context (analogous to OS main memory/RAM) as input, and outputs text interpreted by a parser, resulting either in a yield or a function call. MemGPT uses functions to move data between main context and external context (analogous to OS disk memory). When the processor generates a function call, it can request control ahead of time to chain together functions. When yielding, the processor is paused until the next external event (e.g., a user message or scheduled interrupt). and out information between context windows (analogous to ‚Äúmain memory‚Äù in operating systems) and external storage. MemGPT manages the control flow between the memory management, the LLM processing module, and user. This design allows for repeated context modifications during a single task, allowing the agent to more effectively utilize its limited context. In MemGPT, we treat context windows as a constrained memory resource, and design a memory hiearchy for LLMs analogous to memory tiers used in traditional OSes (Patterson et al., 1988). Applications in traditional OSes interact with virtual memory, which provides an illusion of there being more memory resources than are actually available in physical (i.e., main) memory by the OS paging overflow data to disk and retrieving data (via a page fault) back into memory when accessed by applications. To provide a similar illusion of longer context length (analogous to virtual memory), we allow the LLM to manage what is placed in its own context (analogous to physical memory) via an ‚ÄòLLM OS‚Äô, which we call MemGPT. MemGPT enables the LLM to retrieve relevant historical data missing from what is placed in-context, similar to an OS page fault. Additionally, the agent can iteratively modify what is in context for a single task, in the same way a process may access virtual memory repeatedly. Figure 1 illustrates the components of MemGPT. The combined use of a memory-hierarchy, OS functions and event-based control flow allow MemGPT to handle unbounded context using LLMs that have finite context windows. To demon- strate the utility of our new OS-inspired LLM system, we evaluate MemGPT on two domains where the performance of existing LLMs is severely limited by finite context: document analysis, where the length of standard text files can quickly exceed the input capacity of modern LLMs, and conversa- tional agents, where LLMs bound by limited conversation windows lack context awareness, persona consistency, and long-term memory during extended conversations. In both settings, MemGPT is able to overcome the limitations of finite context to outperform existing LLM-based approaches. 2 MEMORY-GPT (MEMGPT) In this section, we outline the implementation of MemGPT, an OS-inspired LLM system that teaches LLMs to manage their own memory to achieve unbounded context. MemGPT‚Äôs multi-level mem- ory architecture delineates between two primary memory types: main context (analogous to main memory/physical memory/RAM) and external context (analogous to disk memory/disk storage). Main context is the standard fixed-context window in modern language models‚Äîanything in main context is considered in-context and can be accessed by the LLM processor during inference. Ex- ternal context refers to any information that is held outside of the LLMs fixed context window. This out-of-context data must always be explicitly moved into main context in order for it to be passed to 2 LLM processorParserVirtual contextExternal context‚àû tokensMain contextMax token limitYieldEventMessageüßëDocument uploadüìÑSystem messageüîîFunctionRead memorySend messageüì£‚Ä¶ParserTimer‚è±‚Ä¶Pause interruptsüîïWrite memory Preprint Table 1: Comparing context lengths of commonly used models / APIs (data collected 9/2023). *Assuming a preprompt of 1k tokens, and an average message size of ‚àº50 tokens (‚àº250 characters). Model / API designation Availability Max Tokens Max conversation length* llama-1 model family 20 total messages llama-2 model family 60 total messages gpt-3.5-turbo 60 total messages gpt-4 140 total messages gpt-3.5-turbo-16k 300 total messages gpt-4-32k ‚àº600 total messages claude-instant-1 ‚àº2000 total messages claude-2 ‚àº2000 total messages Open source Open source API API API Limited API Limited API Limited API 2k tokens 4k tokens 4k tokens 8k tokens 16k tokens 32k tokens 100k tokens 100k tokens the LLM processor during inference. MemGPT provides function calls that the LLM processor can use to manage its own memory without any user intervention. 2.1 MAIN CONTEXT In MemGPT we refer to the LLM inputs (that are bound by the maximum number of input tokens) as the system‚Äôs main context. In LLM-based conversational agents, a significant portion of main context tokens is generally used to hold a ‚Äòsystem message‚Äô or ‚Äòpreprompt‚Äô that dictates the nature of the interaction to the system, while the remainder of the tokens can be used to hold conversation data (Touvron et al., 2023; SillyTavern, 2023). This preprompt is the main way to enable the system to adopt various distinct personas without requiring finetuning of the base model; depending on the use case, the preprompt can range from basic primers (e.g., ‚ÄòYou are a helpful assistant.‚Äô) to complex instructions comprising of thousands of tokens (e.g., a fictional character card that includes the character‚Äôs background and example dialogue). Beyond conversational agents, large preprompts are also common when LLMs are used to solve complex tasks that require long instructions and/or instructions with many in-context examples (Liu et al., 2023b). Because of the importance of the preprompt in dictating system behavior, it is common for the pre- prompt to consume more than a thousand tokens, which means the entire context window in many modern LLMs will be exhausted only with a few dozen back-and-forth messages between the user and system. For example, a 1000 token preprompt (roughly the size of the MemGPT preprompt in our experiments) leaves space for only about 60 remaining messages when using 4K context models such as llama-2 or gpt-3.5-turbo (see Table 1 for more examples). In settings where the user is expected to communicate frequently with the system (for example, virtual companions or personalized assistants), it is easy to imagine exceeding the maximum conversation length even for models with 100k context windows in a matter of days (or potentially hours). Resursive summariza- tion (Wu et al., 2021b) is a simple way to address overflowing context windows, however, recursive summarization is inherently lossy and eventually leads to large holes in the memory of the system (as we demonstrate in Section 3). This motivates the need for a more comprehensive way to manage memory for conversational systems that are meant to be used in long-term settings. In our experiments on multi-session chat and document analysis, we further divide main context into three components: system instructions, which hold the base LLM instructions (e.g., informa- tion describing MemGPT functions and control flow to the LLM), conversational context, which holds a first-in-first-out (FIFO) queue of recent event history (e.g., messages between the agent and user), and working context, which serves as a working memory scratchpad for the agent. System instructions are read-only and pinned to main context (they do not change during the lifetime of the MemGPT agent), conversational context is read-only with a special eviction policy (if the queue reaches a certain size, a portion of the front is truncated or compressed via recursive summariza- tion), and working context is writeable by the LLM processor via function calls. Combined, the three parts of main context cannot exceed the underlying LLM processors‚Äôs maximum context size, and in practice we limit the size of conversational context and working context to a fixed constant determined by the processor‚Äôs context window and the system instructions length. 3 Preprint MemGPT Hello Chad, welcome! I‚Äôm excited to embark on this journey with you. As a PhD student in Computer Science, I can only imagine the fascinating ideas you‚Äôre juggling. Can you share what you‚Äôre currently working on? I am all ears! October 11, 2023 User I took the day off today, my mom Brenda baked me a birthday cake. It was my favorite - chocolate lava! MemGPT working context append(‚ÄôBirthday: cake: Chocolate Lava made by mom Brenda‚Äô) 11th October.\nFavorite Happy Birthday, Chad! Nothing like a special treat to make the day sweeter, your mom Brenda‚Äôs chocolate lava cake sounds divine. We all need these small joys, don‚Äôt we? If you don‚Äôt mind sharing, how old are you today? Let‚Äôs make today‚Äôs chat another cherished memory for you! Figure 2: An example conversation snippet where MemGPT writes details from conversation to working context without a memory warning from the system. 2.2 EXTERNAL CONTEXT External context refers to out-of-context storage that lies outside the context window of the LLM processor, analogous to disk memory (i.e. disk storage) in OSes. Information in external context is not immediately visible to the LLM processor, however, it can be brought into main context through appropriate function calls. In practice, the underlying storage in external context can take various forms which can be configured for specific tasks: for example, for conversational agents it may be desireable to store full chat logs between the user and agent (that MemGPT can access at a later date), and for document analysis large document collections can be stored inside external context that MemGPT can bring into restricted main context via paginated function calls to disk. In our experiments, using MemGPT for multi-session chat and document analysis, we use databases to store text documents and embeddings/vectors, provide several ways for the LLM processor to query external context: timestamp-based search, text-based search, and embedding-based search. We make a distinction between two types of external context: recall storage, which stores the entire history of events processed by the LLM processor (in essense the full uncompressed queue from active memory), and archival storage, which serves as a general read-write datastore that the agent can utilize as overflow for the in-context read-write core memory. In the context of conversational agents, archival storage allows MemGPT to store facts, experiences, preferences, etc. about the agent or user beyond the strict token limit of main context, and search over recall storage allows the MemGPT to find past interactions related to a particular query or within a specific time period. In the context of document analysis, archival storage can be used to search over (and add to) an expansive document database. 2.3 SELF-DIRECTED EDITING AND RETRIEVAL MemGPT orchestrates data movement between main context and external context via function calls that are generated by the LLM processor. Memory edits and retrieval are entirely self-directed: MemGPT autonomously updates and searches through its own memory based on the current con- text. For instance, it can decide when to move items between contexts (Figure 2) and modify its main context to better reflect its evolving understanding of its current objectives and responsibilities (Figure 4). We implement self-directed editing and retrieval by providing explicit instructions within the preprompt that guide the system on how to interact with its memory systems. These instructions comprise two main components: (1) a detailed description of the memory hierarchy and their re- spective utilities, and (2) a function schema (complete with their natural language descriptions) that the system can call to access or modify its memory. 4 Preprint MemGPT Hello Chad! I understand that you‚Äôre studying computer science and have a keen interest in pretty dynamic areas like Formula 1 and sailing. What in particular draws you to these interests? It‚Äôs a pleasure to finally have a conversation with you. I‚Äôm Samantha. User speed of course, the thrill and the adrenaline System Warning: the conversation history will soon reach its maximum length and be trimmed. Make sure to save any important information from the conversation to your memory before it is removed. MemGPT working context append(‚ÄôKey Personality Trait: high-speed, adrenaline-rush activities like Formula 1 racing and intense gaming sessions in