The paper introduces SemanticGNN, a novel method to learn entity embeddings from both co-engagement and content-based semantic information using a Graph Neural Network (GNN) over a knowledge graph (KG). The authors address challenges in training on a KG within Netflix, such as relation type class imbalance, lack of informative features for semantic concept nodes, and graph scalability. SemanticGNN is trained via a two-step strategy, first pre-training the semantic KG via a KG completion task, and then training a relation-aware GNN using link prediction loss over entity-entity links (EEL) to obtain entity embeddings. The authors propose a distributed training framework to train the model across multiple GPUs and demonstrate that SemanticGNN outperforms baseline GNN-based entity embeddings in recognizing semantic similarity and co-engagement, especially in the inductive setting and for learning new title representations. The method has also been successfully deployed within Netflix.