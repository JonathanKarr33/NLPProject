to this method have been made for transformers to extract attention weights , like the Attention Rollout ( AR ) method ( Jain et al . 2022 ) and the Layer-wise Relevance Propagation ( LRP ) attention method ( Ethem et al . 2022 ) . Another method like Grad-CAM ( Selvaraju et al . 2017 ) has been adapted for transformers to visualize the regions of the image that were influential in making the decisions by the model ( Mehdi et al . 2022 ) . However , these methods are not exclusive to transformers and can be further optimized keeping the architectural differences in mind . Probing Tasks Although probing tasks are specific to probing a par- ticular aspect of the model , they are valuable in explain- ing the decisions made by the model . Probing tasks designed for transformers focus on understanding the multi- modal relationship and complex reasoning tasks . Some inno- vative methods from probing tasks are the Proposed Evaluation Protocol ( PEP ) framework ( Elazar et al . 2022 ) and Visually Guided Development ( VGD ) ( Aman et al . 2022 ) . These methods give a deeper insight into the decision- making process of the models and can help understand not only the output but the inner workings of the model . Attention and its Reliability Attention has been extensively used as an explanation method for transformers to understand the decision-making process of the model . Generally used to visualize and interpret the interactions within the model , recent studies have shown that attention might not always be reliable , espe- cially for multimodal models ( Santoro et al . 2021 ; Goyal et al . 2022 ) . It has been observed that the reasoning behind the attention weights is not always conclusive and can be mis- leading . ( Blum and Liang 2022 ) suggested a more context- dependent and real-time attention mechanism to get a better understanding of the model , while ( Perez et al . 2022 ) proposed a new method called Self-Reflected Attention ( SRA ) to mitigate this issue . Overall , attention has remained an important aspect of interpreting the transformer-based models , but its reliability needs to be questioned , espe- cially for complex multimodal models like VLPMs . Open Challenges and Conclusion We have discussed the current state of VLPMs regarding reliability , focusing on bias , robustness , and interpretability . We have delved deep into these aspects , presenting the current work , methods , and models proposed , while also dis- cussing the open challenges in the field . As we observed , VLPMs continue to grow in accuracy and size , but there are several challenges that need to be addressed , especially from the aspects of bias , robustness , and interpretability . We hope that this survey will not only present the current state of VLPMs but also highlight some research gaps that can help alleviate the overall state of VLPMs.