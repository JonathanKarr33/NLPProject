Introduction
The domain gap manifests when a model, trained on a
source domain with annotated samples, is deployed in a
target domain that has a distribution shift compared to the
source domain. Unsupervised domain adaptation (UDA)
considers a target domain with unlabeled data and aims to
mitigate the domain gap by aligning the source and target
domain distributions using the knowledge learned from the
source domain. Most of the current UDA methods conduct
domain adaptation by either minimizing the source-target
distribution discrepancy [39, 47], or by adversarially align-
ing the feature spaces of the source and target data [7, 9].
However, such models need access to the source data dur-
ing adaptation, and therefore cannot be applied to cases
where the source domain is not available or when the source
data is sensitive or confidential. To address these concerns,
source-free domain adaptation (SFDA) [20, 45] was pro-
posed, where domain adaptation to the target distribution
takes place with a source-pretrained model using only the
unlabelled target data.
While the vast majority of existing UDA literature deals
with closed-set domain adaptation, where the target do-
main and source domain share the same classes, a more
realistic scenario is open-set domain adaptation (OSDA)
[22, 30] where the target domain contains samples belong-
ing to novel classes that are absent in the source domain.
In the OSDA setting, closed-set UDA solutions would en-
force alignment of the source and target feature spaces un-
der the unknown category mismatch, leading to negative
transfer [6] and deteriorating performance. The majority of
the existing OSDA methods [22, 30] utilize domain adver-
sarial learning techniques to align the source domain with
only the known classes in the target domain, leaving out
the target-unknown classes. Such methods fail to properly
learn the features for the unknown classes, and hence no
clear decision boundary between the known classes and the
unknown class in the target domain is realized. Some uni-
versal domain adaptation methods, i.e. UDA methods de-
signed to work in both closed and open-set settings [15, 31],
have attempted to conduct self-supervised learning (SSL)
to discover latent target domain features without explicit
distribution matching. However, such methods fail under
large domain gaps. More recently, [12] proposed a three-
way domain adversarial feature space alignment between
the source domain and the known and the unknown tar-
get subdomains, thus segregating the known and unknown
classes in the target domain.
In this work, we introduce Unknown Sample Discovery
(USD) as a source-free OSDA (SF-OSDA) method that uti-
lizes an ensemble-based pseudolabeling strategy for the tar-
get data, and generates known and unknown target sub-
sets based on Jensen-Shannon distance (JSD) between the
pseudolabels and the predictions from a teacher model.
USD uses 2-component Gaussian Mixture Model (GMM)
to model the target domain JSD, where the distribution with
the lower mean JSD is considered to be of the known class
samples and that with the greater mean JSD is taken as that
consisting of unknown class samples. The known-unknown
target subsets are used to adapt the student model. The
student model is updated with gradient descent, while the
teacher model is updated by exponential moving averages
(EMA) of the teacher and student models. The teacher-
student framework in USD helps to mitigate error accu-
mulation induced from any possibly faulty known-unknown
sample separation.
USD introduces an unknown class output node in the tar-
get model. The adapted target model infers new target sam-
ples in one one of the known classes or the unknown class,
without operating on the entire target dataset first to iden-
tify known and unknown samples. The main contributions
of this work are as follows.
• We introduce USD as an SF-OSDA model that co-trains a
dual-branch teacher-student framework to split the target
domain into known and unknown class subsets.
• USD proposes the Jensen-Shannon distance between the
target pseudolabels and teacher model predictions as an
effective criterion for separating target samples in known
and unknown classes.
• Co-training in USD, aided by weak-strong consistency
between the teacher and student outputs, significantly
mitigates error accumulation resulting from imperfect
known-unknown separation, and sustains the adaptation
performance.
• USD generates reliable pseudolabels from the student
model outputs on an ensemble of weak and strong target
data augmentations.
• USD utilizes curriculum adaptation to progressively learn
the known class feature space first, and the unknown class
feature space later, thus enabling robust alignment of the
entire target space with the source domain.
• Extensive experiments on 3 popular UDA benchmarks
demonstrate the superiority of USD over existing SF-
OSDA methods.
2. Related Works
2.1. Unsupervised domain adaptation
Domain gap originates from the distribution shift between
the source domain where a deep network model is trained,
and the target domain where the model is deployed [39].
This domain gap may be reduced by minimizing the max-
imum mean discrepancy (MMD) [23, 40], or the central
moment discrepancy (CMD) [47] between the distributions
in the source and target domains. Deep CORAL [35]
mitigated domain shift by matching second-order distribu-
tion statistics. [7] introduced the Gradient Reversal Layer
(GRL) and made use of a domain discriminator to adversar-
ially align the source and target distributions in a common
feature space using a common feature encoder. The Ad-
versarial Discriminative Domain Adaptation (ADDA) [41]
method decoupled the feature extraction process by learn-
ing two separate feature encoders for the two domains and
aligned them adversarially to perform classification with a
common classifier.
Generative adversarial networks (GANs) have been uti-
lized to produce images in an intermediate domain be-
tween the source and target to facilitate easier and smoother
adaptation [9]. Domain-wise global adversarial alignment
in the absence of target annotations may lead to loss of
class discrimination in the target embeddings. To align the
domain-wise and class-wise distributions across the source
and target data while maintaining target class feature dis-
crimination, [17] simultaneously solved two complemen-
tary domain-specific and class-specific minimax objectives.
The non-adversarial alignment approach in [27] imposed
a consistency constraint between the labeled source proto-
types and the pseudo-labeled target prototypes in the feature
2.2. Source free domain adaptation
UDA methods that adversarially align the embedding space
[7, 9, 41] or minimize the source-target domain divergence
[23, 40, 47] require access to both the source and target
data during adaptation, rendering them unusable in situa-
tions where the source data is private or restricted. A semi-
supervised UDA method involving a few source representa-
tives or prototypes instead of the full source data was pro-
posed in [4]. Distant supervision for SFDA [19] iteratively
assigned pseudo-labels to the target data and used them to
learn a domain invariant feature space and obtain the tar-
get class centroids. Liang et al.
[20] introduced SHOT
which adapts the source-pretrained feature encoder to the
target domain via self-training with information maximiza-
tion [13, 34] and self-supervised clustering for pseudola-
beling, while transferring the source hypothesis (classifier
model) to the target. To further refine the pseudolabels, [45]
proposed to enforce neighborhood consistency regulariza-
tion among the target samples. To generate compact target
clusters, [46] considered minimizing the distance among K-
nearest neighbors for each target sample and dispersing the
rest by retrieving target features stored in a memory bank.
2.3. Open set domain adaptation
In addition to aligning the source and target subspaces, a
critical step in OSDA is detecting target samples from novel
or unknown categories that are absent in the source do-
main. [11] applied a simple class-wise confidence thresh-
old to reject those samples with lower confidence as un-
known. [30] adversarially aligned the source domain and
known target subdomain, where the unknown target sam-
ples were identified based on a preset threshold. Align-
ment for only the known classes however results in subpar
performance in identifying the unknown samples. The ad-
versarial alignment objective was modified in [22] with an
instance weighting procedure, where higher weights were
given to known target samples and lower weight to un-
known samples. This somewhat smoothened the known-
unknown distinction, but lower weights produced less con-
tributions in the objective loss from the unknown samples,
leading to suboptimal performance. A 3-way domain ad-
versarial alignment between source, known target, and un-
known target in the feature space was proposed in [12]
such that the source and known target are aligned while
the target-unknown gets segregated. [20] and [46] are SF-
UDA methods that also conduct SF-OSDA by separating
the known and unknown samples based on clustering the
sample entropies into two clusters, and taking the cluster
with lower mean entropy as the known subset.
For unsupervised OSDA, we have ns labeled samples
i=1 ∈ Xs, Ys belonging to the source domain Ds,
and nt unlabeled samples {xi
i=1 ∈ Xt belonging to the
target domain Dt. The task of SF-OSDA is to take the
source model fs(θs) : Xs → Ys with model parameters
θs trained on the Cs-multiclass source data {xi
Xs, Ys, and adapt it to ft(θt) : Xt → Yt with model param-
eters θt that can map the {xi
i=1 ∈ Xt to the Ct classes,
where Ct = Cs + 1. The additional class in the target do-
main is a catch-all class for all samples in the target domain
that do not belong to any of the classes in the source domain.
We follow [20] for Source model training follows [20]
to ensure fair comparison with other source-free UDA mod-
els. The source model is trained by minimizing the standard
Figure 1. Pseudolabel generation for the target samples and
known-unknown sample separation based on JSD
Figure 2. Adaptation process for USD using co-training. The stu-
dent model receives pseudolabels for the target samples (see Fig-
ure 1) and is optimized using a combination of triplet, weak-strong
consistency, information maximization (IM) and cross-entropy
losses. The teacher model is updated via exponential moving av-
erages (EMA) at the end of each epoch.
cross entropy loss with label smoothing [26] as follows.
Ls(fs; Xs, Ys) = −Exs∈Xs,ys∈Ys
k log(σk(fs(xs)))
where σk(a) = exp(ak)
i exp(ai) is the k-th element in its softmax
output of a Cs-dimensional vector a, and qls is the one-hot
encoded and smoothed Cs-dimensional vector for sample
k = (1 − α)qk + α/Cs, where qk is 1
for the correct class and 0 for all other classes, and α is the
smoothing factor set at 0.1.
s, such that qls
The source model fs consists of a feature extractor gs :
Xs → Rd and a Cs-class classifier hs : Rd → RCs, such
that fs(x) = hs(gs(x)). USD consists of a student target
t ) and a teacher target model f T
t ). The fea-
ture extractors gS
t , in the student and teacher net-
works respectively, are initialized with the source model
feature extractor, i.e., gS
t = gs. To account for the
novel class samples in the target domain, the source classi-
fier hs is expanded in the student and teacher models to in-
clude an additional trainable output node for the unknown
class. The known class nodes in the target classifiers hS
t , for the student and teacher respectively, are ini-
tialized with hs, and remain frozen during adaptation. The
unknown class nodes in hS
t and the feature extractors
t are adapted using only the unlabeled target samples.
3.1. Known-unknown sample separation
The first step for target adaptation is to reliably separate the
known class samples and the novel class samples in the tar-
get data. This step is visually depicted in Figure 1. In or-
der to generate pseudolabels ˆyt, the target data undergoes
M = 6 number of weak and strong augmentations (1 weak
and 5 strong) based on AutoAugment [5] policy for Ima-
geNet. The softmax output over Cs classes for each aug-
mented view xiM
then averaged over the augmentations, as follows.
is taken from the student model f S
t = arg max
The index corresponding to the maximum averaged soft-
max output is taken as the hard pseudolabel ˆyi
t for each tar-
get sample xi
t. These pseudolabels are however only over
the Cs known classes, and therefore the samples need to be
split into known class subset X K
and unknown class sub-
t . Existing SF-OSDA methods [20, 46] identify un-
known class samples by utilizing the output entropy of the
target data. Entropies for all samples are calculated at the
beginning of each epoch and then normalized in the range
of [0, 1] by dividing the each sample entropy by log Cs. The
normalized entropies are then clustered by 2-class k-means
clustering. The cluster with the higher mean entropy or un-
certainty is considered to be the one containing unknown
samples, while the other cluster with lower mean entropy is
taken as containing known class samples.
Sample separation is a critical component for noisy la-
bel learning (NLL) algorithms where clean and noisy sam-
ples are separated for robust supervised training of a model.
Traditionally, NLL calculates the cross-entropy loss on the
whole dataset and then uses low cross-entropy loss as the
criterion to identify clean samples [1, 16, 18]. In USD, we
conduct known-unknown sample separation for SF-OSDA
based on JSD between the network outputs and their corre-
sponding pseudolabels, which is calculated as follows.
where, KL(a, b) is the Kullback-Leibler divergence be-
tween a and b, and pi
t)) is the output soft-
max probability for target sample xi
t from the target teacher
We consider the unknown class samples in the target do-
main as noisy samples when predictions are made over only
the known Cs classes. In comparison to entropy or cross-
entropy loss, JSD is symmetric by design and ranges be-
tween 0 and 1.As shown in Figure 1, when plotted against
the number of samples, JSD produces a bimodal histogram.
We model the JSD distribution with 2-component Multi-
variate Gaussian Mixture Model (GMM) with equal priors,
resulting in probabilities for each target sample to belong to
either of the two modes. We consider the samples belonging
to the distribution with the lower-mean Gaussian as samples
from one of the known classes, and consider those samples
on the higher-mean Gaussian as coming from the unknown
target class.
t . The pseudolabels ˆyi
Practically, we take the probability wi
t of belonging to
the lower-mean GMM distribution for each target sample
t, and set a lower-bound/threshold δt to select the known
sample subset X K
. The remaining target samples are in-
cluded in the unknown subset X U
updated accordingly, where the known subset retain their
earlier assigned pseudolabel from among the Cs classes,
and the unknown subset of target samples get the new un-
known class pseudolabel |Ct|. It has to be noted that dur-
ing adaptation, the teacher network conducts the known-
unknown sample separation at the beginning of each epoch,
and the student network is adapted over the Ct classes with
the target data.
3.2. Teacher-student co-training and regularization
USD simultaneously adapts the student and teacher tar-
get models, such that the student model parameters θS
updated based on the minibatch gradient descent, and the
teacher network parameters θT
t are updated as temporally
ensembled version of the student network [36] at the end of
each epoch as follows.
+ (1 − m)θS
where, m is the momentum parameter for weight ensem-
bling, and N = 2, 3, .., E is the epoch number. Such co-
training and cross-network sample splitting by the teacher
for the student work to lessen error accumulation from im-
perfect known-unknown sample separation and stabilizes
the adaptation process. USD further maintains weak-strong
temporal consistency between the teacher network outputs
and the student network outputs by minimizing the follow-
ing consistency loss.
t ; Xt) = KL (cid:0)piS
(cid:18) piT
t )) is the softmax output from the
student on an strongly augmented target sample xiS
)) is the softmax output from the teacher
on the weakly augmented version xiW
of the same target
instance. The strong and weak augmentations are done fol-
lowing the AutoAugment [5] ImageNet policy.
USD also utilizes a triplet
loss [33] to effectively
learn the decision boundary between known and unknown
classes. The output zia
)]a of the teacher model
on an weakly augmented known class sample is taken as the
anchor, and the corresponding output zi+
the strongly augmented version of the same sample from the
student model is taken as the positive instance. The negative
instance is the student model output zi−
a randomly chosen unknown class sample. Cosine distance
is taken as the distance metric, and is calculated as follows.
D(z1, z2) = 1 −
||z1||2||z2||2
where z1 and z2 are any two network outputs. Triplet loss
is in turn calculated as follows.
t ; Xt) = max(D(zia
the student network is trained with the
instance-weighted standard cross-entropy loss with label
smoothing [26], as follows.
S ) − D(zia
In addition,
t ; Xt) = −E
log(σk(f S
The instance weights ωi are the probability wi
t for known
target samples xt
t of belonging to the lower-mean
JSD distribution, and (1 − wi
t) for unknown target samples
t of belonging to the higher-mean JSD distribution,
during the known-unknown sample separation. In order to
promote adaptation to the known samples first and to pro-
gressively learn the unknown class feature space, USD uti-
lizes cross-entropy loss under curriculum guidance, dictated
by the curriculum factor γr as follows.
t ) + (1 − γr)Lce
where γr = max(0.5, γr−1(1 − βϵ−Lce
tKr−1 )) such
that, β is a hyperparameter and r is the current itera-
tion number. The ratio Lce
dictates the degree
by which the curriculum factor decreases from the earlier
(r − 1)-th iteration to the current r-th iteration. When loss
tK on the known sample subset increases, γ marginally
decreases to accommodate further adaptation on the known
samples in the subsequent iterations. But if Lce
tK decreases
by a large margin, γ decreases accordingly to progressively
adapt to the unknown samples in the following iterations.
Curriculum guidance balances the adaptation of the target
model to the known and unknown subsets.
To encourage individually precise and globally diverse
predictions, USD further minimizes the information maxi-
mization (IM) [20] loss as formulated in [37, 38].
t ))log(σk(f S
t ))] is the mean softmax
output vector over known target samples in a minibatch.
The overall objective function is therefore,
t ) + Leqdiv
t + ζ1Ltrip
t + ζ2Lcon
where ζ1 and ζ2 are two hyperparameters.
A brief demonstration of the USD domain adaptation
pipeline is presented in Algorithm 1.
Algorithm 1: Pseudocode for USD
Input: Source trained model fs and nt unlabled
target data samples xi
Output: Target adapted student model f S
Initialization: Teacher target model f T
t and student
t , are both initialized
target model f S
with parameters θs from fs
1 for epoch = 1 to E do
Conduct M = 6 weak-strong augmentations
and assign ensemble averaged pseudolabels ˆyi
using eq. (2)
Conduct known (X K
sample separation using JSD between ˆyi
teacher softmax output pi
for i = 1 to nt do
t ) - unknown (X U
Optimize, for each minibatch, student model
t with loss Ltot using eq. (13) and get
new student model parameters θS
Update teacher model f T
model weights θS
weights θT
t using eq. (4)
t using new student
t and current teacher model
4. Experimental Setup
4.1. Datasets
We evaluate USD on three popular domain adaptation
benchmarks: Office-31 [29], Office-Home [42], and
VisDA-C [28]. Office-31 is a small-scale DA dataset with 3
distinct domains, Amazon (A), Webcam (W), and DSLR
(D), consisting of images belonging to 31 classes of ob-
jects found generally in an office environment. Divided
into 4 distinct domains Art (A), Clipart (C), Product (P),
and Real-World (R), Office-Home is a medium-sized DA
dataset which has images of 65 classes of objects found
in contemporary office and home settings. The large-scale
VisDA-C dataset contains images of 12 classes of itemss
over 2 domains: Synthetic (S) and Real (R). Its source do-
main is composed of 152K synthetically rendered 3D im-
ages. The target domain consists of 55K real images taken
from MS COCO dataset [21]. For OSDA, we follow the
shared and target-private dataset splits done in [30].
4.2. Implementation details
For source training, we follow the protocol from [20, 46] for
fair comparison against existing SF-OSDA methods. The
basic structure of the teacher and student models also follow
that of [20, 46], that is, the feature extractor is a ResNet-50
[8], followed by a fully-connected (FC) bottleneck layer, a
batch normalization layer [10], an FC classifier layer, and a
weight normalization layer [32], respectively. The student
target model is trained with an SGD optimizer with momen-
tum of 0.9 and weight decay of 10−3. Due to the difference
in the number of samples in each dataset, USD is adapted
for 40 epochs on Office and for 20 epochs on Office-Home
at β = 0.01, and for 5 epochs on VisDA-C at β = 0.001,
at minibatch size of 64 samples in all cases. The threshold
δt for known-unknown sample separation is set at 0.8, and
the momentum parameter m for temporal ensembling is set
according to schedule in [44] with a maximum at 0.9995.
Further, ζ1 = 0.01 and ζ2 is gradually increased to 0.5
following [14]. All experiments were done on a NVIDIA
4.3. Evaluation metrics
The mean-per-class accuracy OS over all known classes
and the unified unknown class for all the target data may
be considered as a metric for evaluating OSDA. However,
such a metric is dominated by the accuracy on the known
classes, as all the unknown samples are lumped into 1 un-
known class [2]. A better metric is therefore to calculate the
mean-per-class accuracy OS* over only the known classes,
and the accuracy UNK for the unknown class, and then take
the harmonic mean HOS of the two for fair evaluation over
the known and the unknown classes. Mathematically, the
metrics are formulated as follows.
|xt : xt ∈ Di
|xt : xt ∈ Di
|xt : xt ∈ D|Ct|
|xt : xt ∈ D|Ct|
2 × OS∗ × U N K
OS∗ + U N K
t = arg max(σ(f S
t))) is the prediction from the
student model f S
t is the target domain data belong-
ing to class i. In this work, we report OS*, UNK, and HOS
for the evaluated adaptation tasks.
5.1. Overall results
We compare USD to a number of existing UDA methods:
closed-set UDA methods (1) DANN [7], (2) CDAN [24],
open-set UDA methods (3) STA [22], (4) OSBP [30], (5)
PGL [25], (6) OSLPP [43], and (7) UADAL [12]. These
methods however are not source-free. We compare USD to
open-set versions of SF-UDA methods SHOT [20] and AaD
[46]. The open-set results for SHOT and AaD on Office-
Home are provided in their respective publications. We gen-
erate results for Office-31 and VisDA-C using their publicly
released code.
The results on Office-31 over all 6 domain pairs are pre-
sented in Table 1. USD outperforms SHOT and AaD by
∼ 16% and ∼ 3%, respectively in terms of mean HOS. Dis-
tinguishing between known and unknown class samples is
crucial in OSDA, and USD strikes the best balance among
the other SF-OSDA methods. SHOT clearly adapts pri-
marily to the known classes without good adaptation on
the unknown samples. AaD overcompensates in identify-
ing unknown samples at the expense of correctly adapting
to the known classes. USD performs equally well over both
known and unknown classes, leading to higher HOS. USD
also outperforms non-source-free methods STA and PGL,
while being comparable to OSBP.
A comparative evaluation for USD against existing UDA
methods on Office-Home is given in Table 2. USD outper-
forms SHOT and AaD by ∼ 20% and ∼ 2%, respectively in
terms of the average HOS over the 12 domain pairs. Similar
to Office-31, SHOT adapts better to the known classes, but
fails to competently identify unknown samples, while AaD
performs worse on the known classes and better on the un-
known samples. USD is more balanced across the known
and unknown classes and also outperforms non-SF OSDA
methods STA, OSBP and PGL.
Results on VisDA-C are given in the bottom right section
in Table 2. SHOT severely suffers from negative transfer
in the unknown class, while AaD fails to learn the target-
known feature space. USD greatly outperforms SHOT and
AaD, as well as the non-SF method OSBP, while being
comparable to STA in terms of mean HOS.
5.2. Ablation study
A detailed ablation study was performed on the known-
unknown sample selection criterion and on the modeling
of the criterion distribution. The results of the ablation
study on both Office-31 and VisDA-C are given in Table
3. USD uses JSD as the known-unknown sample splitting
criterion, while entropy has been extensively used in exist-
ing OSDA methods (SHOT, AaD, UADAL etc.)
purpose. In addition, cross-entropy (CE) loss is a popular
criterion for separating clean-noisy samples for noisy label
OS* UNK HOS OS* UNK HOS OS* UNK HOS
OS* UNK HOS OS* UNK HOS
OS* UNK HOS OS* UNK HOS
Table 1. Evaluation of USD on Office-31 dataset. * are results computed for the methods using publicly released code.
Office-Home
OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS
Office-Home
OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS
Table 2. Evaluation of USD on Office-Home and VisDA-C datasets. * are results computed for the methods using publicly released code.
learning (NLL) algorithms [1, 16, 18]. We evaluate all three
criteria to find the best performing one. The criterion distri-
bution can be modelled by either Gaussian Mixture Model
(GMM) or a Beta Mixture Model (BMM). UADAL mod-
els sample entropy distribution using BMM to distinguish
between known and unknown samples. Our results in Ta-
ble 3 show that modeling the distribution of the JSD with
a GMM outperforms all of the other combinations for un-
known sample discovery.
The effect of the JSD threshold δt for known-unknown
separation on the final HOS is shown in Figure 3. The per-
formance is relatively uniform, which suggests robustness
of adaptation to the hyperparameter δt. Nonetheless, if the
threshold is set too high (such as 0.9), too few samples may
be denoted as known samples, and this could lead to inferior
performance.
Table 4 shows the impact of different components of
our objective function and the effects of our teacher-student
co-training scheme on the final adaptation performance
It is evident that each of our losses
for Office-Home.
) contributes to the adaptation, and leav-
ing out any one of them hurts performance. We observe that
curriculum guidance considerably benefits adaptation and
the final average HOS increases by > 1.5% (from 64.2%
to 65.9%) when such guidance is included. Notably, with-
out curriculum, adaptation to the known classes is impacted
drastically (OS* falls by ∼ 6%), signalling that progres-
sively learning the known class subspace first and then the
unknown class subspace later is the superior strategy.
The final row in Table 4 presents results in the absence
of the teacher network, where the student network conducts
the known-unknown sample separation for itself. Both the
weakly and strongly augmented samples are fed through the
student network, and losses Ltrip
are calculated over
the student model outputs between the weak and strong aug-
mentations. Empirical results clearly show that co-training
in a teacher-student framework is pivotal for mitigating the
effect of any imperfect known-unknown separation and av-
Separation
Distribution
OS* UNK HOS OS* UNK HOS OS* UNK HOS
OS* UNK HOS OS* UNK HOS
OS* UNK HOS OS* UNK HOS
OS* UNK HOS
Table 3. Evaluation of separation criterion and distribution modeling for known-unknown sample separation in USD on Office dataset.
USD w/o Ltrip
USD w/o Lcon
USD w/o LIM
OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS
USD w/o curriculum 47.5
USD w/o co-training
OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS
USD w/o curriculum 46.1
USD w/o co-training
USD w/o Ltrip
USD w/o Lcon
USD w/o LIM
Table 4. Ablation study on the objective function, and co-training for USD on Office-Home dataset.
OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS
OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS OS* UNK HOS
Pseudolabel
Student Predictions
Pseudolabel
Student Predictions
Table 5. Ablation study on the pseudolabeling scheme for USD on Office-Home dataset.
erage HOS over the 12 domain pairs in Office-Home de-
creases by ∼ 5% when the teacher network is removed. As
seen in Figure 4, in the absence of co-training, the student
model adapts faster, but its performance drops from its peak
during the course of adaptation due to error accumulation.
In contrast, adaptation with co-training is slightly slower but
maintains its peak performance.
The effect of the pseudolabeling scheme on the adap-
tation performance for Office-Home is shown in Table 5.
SHOT and AaD use a self-supervised clustering process
built on DeepCluster [3] to get pseudolabels for the known
samples. We see that such clustering is not better than tak-
ing the hard predictions from the student model as pseudola-
bels. In open set settings, the unknown samples can drift the
known class centroids, leading to faulty clusters. Our multi-
view augmentation ensembled pseudolabeling strategy out-
performs both pseudolabeling from clustering or direct stu-
dent predictions.
