Robotics, as a technology,
aims to minimize the necessity for human involvement in
various work processes.
While speech recognition involves the
system comprehending spoken words, it does not necessarily
grasp their meaning[1].
The
initial step involves processing a voice command through
the Android platform, where the conversion of voice to text
occurs within the system.
This platform
is chosen for its simplicity compared to other development
platforms, and the Google speech recognizer is employed for
an effective system response.
The Bluetooth
technology utilized for automation is cost-effective compared
to alternative communication platforms like Zigbee, GSM
(Global System for Mobile Communication), and General
Packet Radio Service (GPRS), with a simple installation
process.
Furthermore, the integration of a mo-
tor driver and relay driver module with Arduino enhances
the effectiveness of driving output
loads.
This paper also
emphasizes real-time surveillance and automation concepts,
incorporating an obstacle detection and avoidance mechanism
facilitated by the ultrasonic sensor HCSR04.
The ultrasonic
sensor measures the distance between the target and the robot’s
actual position.
This is achieved by transmitting an ultrasonic
wave that reflects off a target, and the time taken for the echo
to return helps calculate the distance.
The robot’s movement
is determined based on the distance measurement by the
ultrasonic sensor, and this concept is implemented through
programming in the Arduino IDE (Integrated Development
Environment) and loading it onto the Arduino Atmega 328.
The subsequent sections of this paper are organized to pro-
vide a comprehensive understanding of the development of
this technology.
In Section III,
the simulation of this concept has been executed using Pro-
teus simulation software, and the results are presented.
The
programming concept of the robot is elucidated in Section IV,
detailing the software aspects essential for its functionality.
Moving on to Section V,
the design architecture of this
technology is thoroughly depicted, offering insights into the
overall structural framework.
Similarly, Section VI is dedicated
to the hardware implementation of this concept.
It provides a
detailed account of how the theoretical concepts are translated
into a physical system, including the integration of components
such as motor drivers, relay modules, and Arduino boards.
TECHNICAL COMPONENTS
The first essential technical component for this project is
the Arduino Uno (Figure1), a microcontroller based on the
Atmega328[2].
The inclusion of a 16 MHz ceramic
resonator[1] and the incorporation of all necessary circuitry
within a single module contribute to the operational simplicity
of the Arduino Uno.
In
practice, the module operates within a range of 50 meters[1].
4: PCB design artwork view[1]
E. Ultrasonic Sensor HCSR04
The interfacing mechanism between an Arduino and the
ultrasonic sensor HCSR04 involves measuring the distance
between a target and the real position of the sensor.
This
is achieved by calculating the time duration between the
transmission and reception of an ultrasonic wave.
The Android application (Figure7) serves as the primary
interface for voice signals and has been developed using
the MIT App Inventor[3] platform, employing a drag-and-
drop programming approach.
The application operates based
on Bluetooth and internet connectivity and was designed
with the utilization of the Google Voice Recognizer module.
Subse-
quently, this message is transmitted to an electronic hardware
through Bluetooth connectivity.
This approach allows for a responsive and
conditional control mechanism where the system’s behavior is
grammed sequence.
The simulation of the concept is presented
in Figure8.
When serial data is available, the program reads the bytes from
Bluetooth, initiates string processing, and checks the received
string against predefined voice commands.
Figure9 illustrates the code for ultrasonic sensor
interfacing with an Arduino, while Figure10 depicts the code
for string processing.
Similarly, Figure11 showcases the code
for voice command execution, and Figure12 introduces the
concept of automation, demonstrating the control of light-
ing and horn mechanisms through voice commands.
In this
program, the voice is defined as a string, and parameters
such as distance, duration, and safety distance are declared
as integer, long, and integer, respectively.
The ultrasonic sensor is employed for obstacle detection and
avoidance, a crucial condition applied to the robot.
Distance measurement is facilitated
by the pulse received from digital pin 6 of an Arduino,
utilized as the echo pin in our project.
Upon detecting an obstacle, the
robot halts immediately, moves backward, and takes a left
direction, as per the code depicted in Figure9.
The robot
ceases its movement within 10 centimeters of obstacles, and
after completing subsequent movements, the safety distance
condition is removed from the programming loop.
In real-
world operation, when the user provides a voice command
through an Android application and the string check condition
becomes true, the program executes based on the function
call within that particular condition.
Figures13 (design architecture) and14
(block diagram) depict the different sections of the project,
encompassing two main components: an Android application
and a robot equipped with a wheel mechanism, light, and
buzzer.
In this methodology, wireless communication is estab-
lished through serial communication, where one bit at a time
is transmitted and can be processed by a controller.
HARDWARE IMPLEMENTATION
This section provides a detailed account of how the theo-
retical concepts are translated into a physical system, encom-
passing the integration of components like motor drivers, relay
Fig.
Using this platform, a
circuit can be drawn, and the programming file in hexadecimal
format—generated after compiling the program in the Arduino
IDE—can be uploaded.
The communication
platform is established through the virtual terminal, and a
circuit has been identified that operates according to a pro-
Fig.
In the hardware testing phase,
rigorous evaluation and validation were conducted to ensure
Fig.
This involved
testing the responsiveness of the motor drivers, assessing the
reliability of the relay modules, and confirming the proper
integration of Arduino boards within the system.
The objective
of this phase was to identify and address any potential issues
before proceeding to the full-scale hardware implementation.
14: Block Diagram[1]
cess of hardware testing, ensuring the reliability of individual
components, followed by the successful physical development
of the robot.
The figures provide a visual representation of both
the testing and implementation phases, offering a complete
understanding of the hardware journey in the realization of
the voice recognition robot concept.
13: Design Architecture[1]
Figure15 illustrates the hardware testing process, showcasing
the systematic evaluation of individual components and their
collective functionality.
Moving forward, the hardware implementation
phase involved the physical development of the robot, inte-
grating the tested components into a cohesive and functional
system.
The construction included mounting the motor drivers,
relay modules, and Arduino boards onto the robot chassis,
aligning with the design architecture presented in earlier
sections.
Figure16 visually represents the completed hardware
implementation, illustrating the integrated components within
the physical structure of the robot.
The design carefully
incorporates voice recognition technology, highlighting how
the hardware components seamlessly interact with the software
The integration of voice recognition technology into the
physical robot marks a crucial advancement, bringing the con-
cept to life.
