While
generative AI is currently ubiquitous in the scien-
tific literature and public debate, it has not (yet)
replaced discriminative AI for information extrac-
tion tasks like NER.
Popular open source frameworks, like
the ones provided by HuggingFace (Wolf et al.,
2020; Lhoest et al., 2021; Von Werra et al., 2022),
greatly facilitate the use of such models.
Private datasets
may be stored on local filesystems or be created
using annotation tools.
(ii) Data for NER is processed on three differ-
ent levels: tokens, words and entities.
At
training time, labels for tokens that are not the first
token of a word may be ignored (word level) or
included (token level) in the computation of the
loss.
Finally, while model predictions are often
made on the entity level, some use cases may re-
quire predictions on the word level, for instance if
the associated probabilities are to be used for ac-
tive learning.
(iii) There exists a multitude of NER-specific an-
notation schemes and variants and it is important
to be aware of the differences.
For instance, during
data preprocessing, existing word or entity labels
need to be mapped to token labels, which is an an-
notation scheme dependent process.
At evaluation
time, there are different ways to cope with predic-
tions that do not obey the rules of the given annota-
tion scheme (we will get back to this in Sec.
For instance, while a
small dataset often requires more training epochs,
larger datasets can usually be trained for fewer
The aim of nerblackbox is to provide a high-level
framework which makes the usage of SOTA NER
models as simple as possible.
3, it offers easy access to datasets from
various sources, automated training and evaluation
as well as simple but versatile model inference.
It
does so by hiding all technical complications from
the user2 and is targeted at developers as well as
people who are not necessarily experts in machine
learning or NLP.
This might
make the library appealing also for researchers and
2 Related Work
commonly used framework for
transformer-based NLP is arguably the Hugging-
Face ecosystem, in particular the open source
libraries transformers (Wolf et al., 2020), datasets
(Lhoest et al., 2021) and evaluate (Von Werra
et al., 2022).
High-level libraries that are build on top of trans-
formers exist in the form of Simple Transformers
(Rajapakse, 2019) and T-NER (Ushio and Camacho-
Collados, 2021).
T-NER is specific to
2This is where the name nerblackbox stems from: The
framework does not require any knowledge about internal
processes and can be used as a black box by only specify-
ing inputs (pretrained model, dataset) and using the outputs
(fine-tuned model).
Note that there is no direct relation to
explainability.
However, as will be discussed in the following
sections, nerblackbox offers many unique and pow-
erful features that—to the best of our knowledge—
make it distinct from any existing frameworks.
It does so
in terms of the following classes:
1 >> from nerblackbox import Dataset ,
Training , Model
A high-level overview of the involved compo-
nents is shown in Fig.
Some datasets are pretok-
enized and split into training/validation/test subsets,
while others are not.
The set_up() method auto-
matically deals with these challenges and makes
sure that every dataset, irrespective of the source,
is transformed into a standard format4.
3Currently, the two commonly used (open source) annota-
tion tools LabelStudio (Tkachenko et al., 2020) and Doccano
(Nakayama et al., 2018) are supported.
3.2 Training
In order to train a model, one only needs to choose
a name for the training run (for later reference) and
specify the model and dataset names, like so:
Similar to evaluation, both NER models trained
using nerblackbox and models taken directly from
HuggingFace (HF) can be used for inference.
run ()
In order to ensure stable results irrespective of
the dataset, the training employs well-established
hyperparameters by default (Mosbach et al., 2021).
In particular, a specific learning rate schedule (Stol-
lenwerk, 2022) based on early stopping and warm
restarts (Loshchilov and Hutter, 2017) is used to
accommodate different dataset sizes.
3.3 Evaluation
Any NER model, whether it was trained using
nerblackbox or is taken directly from Hugging-
Face (HF), can be evaluated on any dataset that
is accessible via nerblackbox (see Sec.
All metrics are determined
both on the entity and word level.
In ad-
dition, a model can be applied directly to a file
containing raw data, which may be useful for infer-
ence at large scale (e.g.
4 Advanced Usage
The nerblackbox workflow and the API are de-
signed to be as simple as possible and to con-
ceal technical complications from the user.
How-
ever, they are also highly customizable in terms
of optional function arguments, which may be par-
ticularly interesting for machine learning experts
and researchers.
In this section, we are going to
cover a non-exhaustive selection of nerblackbox’s
advanced features, with a slight emphasis on the
training part.
In par-
ticular, all aspects of the learning rate schedule
(e.g.
Among them
are the learning rate schedules from (Devlin et al.,
2019) and (Mosbach et al., 2021), which may work
well for larger and smaller datasets, respectively.
4.2 Dataset Pruning
nerblackbox provides the option to only use a sub-
set of the training, validation or test data by spec-
ifying parameters like train_fraction .
This may
be useful to accelerate the training (for instance
in the development phase of a product) or if one
wants to investigate the effect of the dataset size
(for instance to see if the model has saturated, or
for research).
4.3 Annotation Schemes
While every dataset is associated with a certain an-
notation scheme, nerblackbox provides the option
to translate between schemes at training time.
This
may be interesting for users who aim to optimize
their model’s performance as well as researchers
who systematically want to investigate the impact
of the annotation scheme.
4.4 Multiple Runs
Since the training of a neural network includes
stochastic processes, the performance of the result-
ing model depends on the employed random seed.
In order to gain control over the associated statis-
tical uncertainties, one may train multiple models
using different random seeds.
With nerblackbox,
this can trivially be done by setting the training
parameter multiple_runs to an integer greater than
1.
In that case, the evaluation metrics will be given
in terms of the mean and its associated uncertainty.
4.6 Careful Evaluation
A model may predict labels for a sequence of to-
kens that are inconsistent with the employed anno-
tation scheme.
When translated to entity predictions,
nerblackbox ignores incorrect labels by default,
both at evaluation and inference time.
However,
the popular evaluate (Von Werra et al., 2022) and
seqeval (Nakayama, 2018) libraries do take incon-
sistent predictions into account during evaluation.
4.7 Compatibility with transformers
nerblackbox is heavily based on transformers (Wolf
et al., 2020) such that compatibility is guaranteed.
In particular, the Model class has the attributes
tokenizer and model , which are ordinary trans-
formers classes and can be used as such.
It includes a pedagogical introduction
to the library, an in-depth discussion of its fea-
tures as well as docs for the python API.
Consis-
tent code syntax and typing are ensured by usage
of black9 and mypy10, respectively.
As an additional cross-
check, numerical results from the literature are re-
produced using nerblackbox (details can be found
in the documentation).
In Proceedings of
the 16th Conference of the European Chapter of the
Association for Computational Linguistics: System
Demonstrations, pages 53–62, Online.
In Proceedings of the 2022 Conference on
Empirical Methods in Natural Language Processing:
System Demonstrations, pages 128–136, Abu Dhabi,
UAE.
